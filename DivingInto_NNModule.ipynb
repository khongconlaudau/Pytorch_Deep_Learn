{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097968a3-9690-4638-a42d-03d0bcbed41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "    content = requests.get(URL + FILENAME).content\n",
    "    (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0826b8-df0e-44b4-923c-8ddbf683a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset is in numpy array format, and has been stored using pickle, a python-specific format for serializing data.\n",
    "import pickle \n",
    "import gzip\n",
    "\n",
    "#This converts the Path object into a string in POSIX format (i.e., uses forward slashes / as separators).\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d376ba86-a3be-4e0c-937c-c3cc3199fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7d235b-5356-4a28-92c9-bc2d8208a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0].reshape((28,28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49218e90-8e30-478d-99d2-7d3ca875fbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    lambda x: x.detach().clone(), (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab2a9b-45cc-4798-ae64-503a4c38bbbd",
   "metadata": {},
   "source": [
    "## Neural net from scratch (without torch.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed69367f-b743-4fdc-b4e5-fb95640a1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "weights = torch.rand(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f110548c-8cd3-433e-822f-912575e8f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "871439ef-1d3f-41fb-9f2d-6a6d8f57294f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
       "         -2.3026, -2.3026], grad_fn=<SelectBackward0>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64 # batch size \n",
    "\n",
    "xb = x_train[:bs].float()\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4309a069-b92c-4993-890a-a9b0c7e577d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "49854d7e-21d7-4fd0-a9b8-a5f7523dcdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3026, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_func = nll\n",
    "\n",
    "yb = y_train[:bs]\n",
    "print(loss_func(preds, yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b52009b3-a70a-443d-b6ac-1b5239532b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3d94f13-09b1-4e50-9757-512d32b817bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1094)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3d1352b7-3cc7-4f78-b8bf-ccef1f235cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1): # This is a math trick to simulate math.ceil(n / bs) without importing math\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i].float()\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "14fb5dbc-f772-4561-b125-0d9dfd8bee6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.2851, grad_fn=<NegBackward0>), tensor(0.1875))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b30d9d9-1917-4690-99c7-6660242129c7",
   "metadata": {},
   "source": [
    "# Using torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f636e4d-bdc1-43dd-833e-d7b9bfb3c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "63513522-606e-4590-81f9-858d816bfc7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: __int64 != float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_func(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m, yb), accuracy(model(xb), yb))\n",
      "Cell \u001b[1;32mIn[122], line 6\u001b[0m, in \u001b[0;36mmodel\u001b[1;34m(xb)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodel\u001b[39m(xb):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m \u001b[38;5;241m+\u001b[39m bias\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: __int64 != float"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277a387-99f2-4ea6-929b-a5cd65251257",
   "metadata": {},
   "source": [
    "### Refactor using nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9e404dc3-18c3-440f-9b67-d4ea7cb17812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.rand(784, 10,  dtype=torch.float) / math.sqrt(784), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.zeros(10,  dtype=torch.float), requires_grad=True)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "01c17c42-f401-48b3-81f4-ff34e585ac0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3026, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Mnist_Logistic()\n",
    "xb = xb.float()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9d62321c-7324-432f-b3ef-9ab59b2f0c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3026, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863ec3d-0237-43ea-bf48-fc4941cd81a4",
   "metadata": {},
   "source": [
    "### Refactor using torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "71359382-a2e7-4fd8-9575-64c5651b0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a666229b-7c6e-4ef4-8f20-2745969b60ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3026, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2851, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i].float()\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "print(loss_func(model(xb), yb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dacf926-5a1c-49ee-9df5-0c3755a5af21",
   "metadata": {},
   "source": [
    "### Refactor using Dataset\n",
    "\n",
    "#### Previously, we had to iterate through minibatches of x and y values separately:\n",
    "- xb = x_train[start_i:end_i]\n",
    "- yb = y_train[start_i:end_i]\n",
    "\n",
    "#### Now, we can do these two steps together:\n",
    "- from torch.utils.data import TensorDataset\n",
    "- train_ds = TensorDataset(x_train, y_train)\n",
    "- xb,yb = train_ds[i*bs : i*bs+bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "65b8005d-e39a-4ac1-a0c0-060666f6f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "10ebfd0c-8fcb-4e06-8c02-c3f05c92b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "df759a50-c90a-4fa8-a30e-a76b206c555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2851, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs : i * bs + bs]\n",
    "        pred = model(xb.float())\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb.float()), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2f0a0-8d47-40b0-aab2-7546c811f1cf",
   "metadata": {},
   "source": [
    "### Refactor using DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "515eab67-9a3b-4184-906d-0674fc37f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "011f283b-30e3-47ed-8169-7a0757b06179",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c197f54c-e6f7-4d42-ac7d-0256c024e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2851, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb.float())\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "print(loss_func(model(xb.float()), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e5796-5470-4016-ab8a-0c3e77d46b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
